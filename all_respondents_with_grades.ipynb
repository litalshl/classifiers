{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>All Respondents Analysis with Grades</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read All Respondents Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Anger  Contempt   Disgust      Fear       Joy   Sadness  Surprise  \\\n",
      "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "3            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "147733       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "147734  0.195341  0.187637  0.027562  0.130503  0.043328  0.117269  0.057809   \n",
      "147735  0.245047  0.204197  0.028027  0.133038  0.041089  0.118906  0.057576   \n",
      "147736       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "147737       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "        Engagement  Valence  Sentimentality  ...  Saccade Index by Stimulus  \\\n",
      "0              NaN      NaN             NaN  ...                        NaN   \n",
      "1              NaN      NaN             NaN  ...                        NaN   \n",
      "2              NaN      NaN             NaN  ...                        NaN   \n",
      "3              NaN      NaN             NaN  ...                        NaN   \n",
      "4              NaN      NaN             NaN  ...                        NaN   \n",
      "...            ...      ...             ...  ...                        ...   \n",
      "147733         NaN      NaN             NaN  ...                        NaN   \n",
      "147734    0.328766      0.0        0.645367  ...                        NaN   \n",
      "147735    0.328766      0.0        0.701570  ...                        NaN   \n",
      "147736         NaN      NaN             NaN  ...                        NaN   \n",
      "147737         NaN      NaN             NaN  ...                        NaN   \n",
      "\n",
      "        Saccade Start  Saccade End  Saccade Duration  Saccade Amplitude  \\\n",
      "0                 NaN          NaN               NaN                NaN   \n",
      "1             36046.4      36190.9             144.5          10.863743   \n",
      "2             36046.4      36190.9             144.5          10.863743   \n",
      "3             36046.4      36190.9             144.5          10.863743   \n",
      "4                 NaN          NaN               NaN                NaN   \n",
      "...               ...          ...               ...                ...   \n",
      "147733      2522535.8    2523204.8             669.0          13.749534   \n",
      "147734            NaN          NaN               NaN                NaN   \n",
      "147735            NaN          NaN               NaN                NaN   \n",
      "147736            NaN          NaN               NaN                NaN   \n",
      "147737            NaN          NaN               NaN                NaN   \n",
      "\n",
      "        Saccade Peak Velocity  Saccade Peak Acceleration  \\\n",
      "0                         NaN                        NaN   \n",
      "1                  187.888661                1271.556906   \n",
      "2                  187.888661                1271.556906   \n",
      "3                  187.888661                1271.556906   \n",
      "4                         NaN                        NaN   \n",
      "...                       ...                        ...   \n",
      "147733             185.949516                4693.041627   \n",
      "147734                    NaN                        NaN   \n",
      "147735                    NaN                        NaN   \n",
      "147736                    NaN                        NaN   \n",
      "147737                    NaN                        NaN   \n",
      "\n",
      "        Saccade Peak Deceleration  Saccade Direction  Respondent  \n",
      "0                             NaN                NaN         001  \n",
      "1                    -1870.865410          39.448696         001  \n",
      "2                    -1870.865410          39.448696         001  \n",
      "3                    -1870.865410          39.448696         001  \n",
      "4                             NaN                NaN         001  \n",
      "...                           ...                ...         ...  \n",
      "147733               -4362.382069         331.759749         019  \n",
      "147734                        NaN                NaN         019  \n",
      "147735                        NaN                NaN         019  \n",
      "147736                        NaN                NaN         019  \n",
      "147737                        NaN                NaN         019  \n",
      "\n",
      "[1533702 rows x 77 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder path where the CSV files are located\n",
    "folder_path = \"all respondents data\"\n",
    "\n",
    "# Initialize an empty dataframe to store the combined data\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each file in the folder with .csv extension and append to the combined_data dataframe\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        respondent_num = filename.split('_')[0]  # Get the first part of the filename before the first '_'\n",
    "        df['Respondent'] = respondent_num  # Add a new column with the respondent number\n",
    "        combined_data = pd.concat([combined_data, df])\n",
    "\n",
    "columns_to_remove = ['Row','Timestamp','EventSource','SlideEvent','StimType','Duration',\n",
    "                     'CollectionPhase','SourceStimuliName','EventSource','SampleNumber','EventSource.1',\n",
    "                     'Blink', 'BlinkRate', 'EventSource.2', 'ET_TimeSignal', 'EventSource.3']\n",
    "combined_data.drop(columns_to_remove, axis=1, inplace=True)\n",
    "\n",
    "# Print the combined data\n",
    "print(combined_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Anger  Contempt   Disgust      Fear       Joy   Sadness  Surprise  \\\n",
      "0             NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "1             NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2             NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "3             NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "4             NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "1533697       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "1533698  0.195341  0.187637  0.027562  0.130503  0.043328  0.117269  0.057809   \n",
      "1533699  0.245047  0.204197  0.028027  0.133038  0.041089  0.118906  0.057576   \n",
      "1533700       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "1533701       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "         Engagement  Valence  Sentimentality  ...  Saccade Start  Saccade End  \\\n",
      "0               NaN      NaN             NaN  ...            NaN          NaN   \n",
      "1               NaN      NaN             NaN  ...        36046.4      36190.9   \n",
      "2               NaN      NaN             NaN  ...        36046.4      36190.9   \n",
      "3               NaN      NaN             NaN  ...        36046.4      36190.9   \n",
      "4               NaN      NaN             NaN  ...            NaN          NaN   \n",
      "...             ...      ...             ...  ...            ...          ...   \n",
      "1533697         NaN      NaN             NaN  ...      2522535.8    2523204.8   \n",
      "1533698    0.328766      0.0        0.645367  ...            NaN          NaN   \n",
      "1533699    0.328766      0.0        0.701570  ...            NaN          NaN   \n",
      "1533700         NaN      NaN             NaN  ...            NaN          NaN   \n",
      "1533701         NaN      NaN             NaN  ...            NaN          NaN   \n",
      "\n",
      "         Saccade Duration  Saccade Amplitude  Saccade Peak Velocity  \\\n",
      "0                     NaN                NaN                    NaN   \n",
      "1                   144.5          10.863743             187.888661   \n",
      "2                   144.5          10.863743             187.888661   \n",
      "3                   144.5          10.863743             187.888661   \n",
      "4                     NaN                NaN                    NaN   \n",
      "...                   ...                ...                    ...   \n",
      "1533697             669.0          13.749534             185.949516   \n",
      "1533698               NaN                NaN                    NaN   \n",
      "1533699               NaN                NaN                    NaN   \n",
      "1533700               NaN                NaN                    NaN   \n",
      "1533701               NaN                NaN                    NaN   \n",
      "\n",
      "         Saccade Peak Acceleration  Saccade Peak Deceleration  \\\n",
      "0                              NaN                        NaN   \n",
      "1                      1271.556906               -1870.865410   \n",
      "2                      1271.556906               -1870.865410   \n",
      "3                      1271.556906               -1870.865410   \n",
      "4                              NaN                        NaN   \n",
      "...                            ...                        ...   \n",
      "1533697                4693.041627               -4362.382069   \n",
      "1533698                        NaN                        NaN   \n",
      "1533699                        NaN                        NaN   \n",
      "1533700                        NaN                        NaN   \n",
      "1533701                        NaN                        NaN   \n",
      "\n",
      "         Saccade Direction  Respondent  Grade  \n",
      "0                      NaN         001  100.0  \n",
      "1                39.448696         001  100.0  \n",
      "2                39.448696         001  100.0  \n",
      "3                39.448696         001  100.0  \n",
      "4                      NaN         001  100.0  \n",
      "...                    ...         ...    ...  \n",
      "1533697         331.759749         019   55.0  \n",
      "1533698                NaN         019   55.0  \n",
      "1533699                NaN         019   55.0  \n",
      "1533700                NaN         019   55.0  \n",
      "1533701                NaN         019   55.0  \n",
      "\n",
      "[1533702 rows x 78 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in the Grades.csv file\n",
    "grades_df = pd.read_csv('Grades.csv')\n",
    "\n",
    "# Remove the trailing underscore from the \"Respondent\" column in the grades_df dataframe\n",
    "grades_df['Respondent'] = grades_df['Respondent'].str.rstrip('_')\n",
    "\n",
    "# Merge the combined_data and grades_df dataframes based on the \"Respondent\" column\n",
    "combined_data_with_grades = pd.merge(combined_data, grades_df[['Respondent', 'Grade']], on='Respondent')\n",
    "\n",
    "# Print the resulting dataframe with the added \"Grade\" column\n",
    "print(combined_data_with_grades)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Anger', 'Contempt', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise',\n",
      "       'Engagement', 'Valence', 'Sentimentality', 'Confusion', 'Neutral',\n",
      "       'Attention', 'Brow Furrow', 'Brow Raise', 'Cheek Raise', 'Chin Raise',\n",
      "       'Dimpler', 'Eye Closure', 'Eye Widen', 'Inner Brow Raise', 'Jaw Drop',\n",
      "       'Lip Corner Depressor', 'Lip Press', 'Lip Pucker', 'Lip Stretch',\n",
      "       'Lip Suck', 'Lid Tighten', 'Mouth Open', 'Nose Wrinkle', 'Smile',\n",
      "       'Smirk', 'Upper Lip Raise', 'Pitch', 'Yaw', 'Roll',\n",
      "       'Interocular Distance', 'ET_PupilLeft', 'ET_PupilRight',\n",
      "       'ET_DistanceLeft', 'ET_DistanceRight', 'ET_GazeLeftx', 'ET_GazeLefty',\n",
      "       'ET_GazeRightx', 'ET_GazeRighty', 'ET_ValidityLeftEye',\n",
      "       'ET_ValidityRightEye', 'ET_CameraLeftX', 'ET_CameraLeftY',\n",
      "       'ET_CameraRightX', 'ET_CameraRightY', 'Gaze X', 'Gaze Y',\n",
      "       'Interpolated Gaze X', 'Interpolated Gaze Y', 'Interpolated Distance',\n",
      "       'Gaze Velocity', 'Gaze Acceleration', 'Fixation Index',\n",
      "       'Fixation Index by Stimulus', 'Fixation X', 'Fixation Y',\n",
      "       'Fixation Start', 'Fixation End', 'Fixation Duration',\n",
      "       'Fixation Dispersion', 'Saccade Index', 'Saccade Index by Stimulus',\n",
      "       'Saccade Start', 'Saccade End', 'Saccade Duration', 'Saccade Amplitude',\n",
      "       'Saccade Peak Velocity', 'Saccade Peak Acceleration',\n",
      "       'Saccade Peak Deceleration', 'Saccade Direction', 'Respondent',\n",
      "       'Grade'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(combined_data_with_grades.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Facial Expressions Analysis</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Pre-processing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondent</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Contempt</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Engagement</th>\n",
       "      <th>...</th>\n",
       "      <th>Lip Suck</th>\n",
       "      <th>Lid Tighten</th>\n",
       "      <th>Mouth Open</th>\n",
       "      <th>Nose Wrinkle</th>\n",
       "      <th>Smile</th>\n",
       "      <th>Smirk</th>\n",
       "      <th>Upper Lip Raise</th>\n",
       "      <th>Pitch</th>\n",
       "      <th>Yaw</th>\n",
       "      <th>Roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Respondent  Grade  Anger  Contempt  Disgust  Fear  Joy  Sadness  Surprise  \\\n",
       "0        001  100.0    NaN       NaN      NaN   NaN  NaN      NaN       NaN   \n",
       "1        001  100.0    NaN       NaN      NaN   NaN  NaN      NaN       NaN   \n",
       "2        001  100.0    NaN       NaN      NaN   NaN  NaN      NaN       NaN   \n",
       "3        001  100.0    NaN       NaN      NaN   NaN  NaN      NaN       NaN   \n",
       "4        001  100.0    NaN       NaN      NaN   NaN  NaN      NaN       NaN   \n",
       "\n",
       "   Engagement  ...  Lip Suck  Lid Tighten  Mouth Open  Nose Wrinkle  Smile  \\\n",
       "0         NaN  ...       NaN          NaN         NaN           NaN    NaN   \n",
       "1         NaN  ...       NaN          NaN         NaN           NaN    NaN   \n",
       "2         NaN  ...       NaN          NaN         NaN           NaN    NaN   \n",
       "3         NaN  ...       NaN          NaN         NaN           NaN    NaN   \n",
       "4         NaN  ...       NaN          NaN         NaN           NaN    NaN   \n",
       "\n",
       "   Smirk  Upper Lip Raise  Pitch  Yaw  Roll  \n",
       "0    NaN              NaN    NaN  NaN   NaN  \n",
       "1    NaN              NaN    NaN  NaN   NaN  \n",
       "2    NaN              NaN    NaN  NaN   NaN  \n",
       "3    NaN              NaN    NaN  NaN   NaN  \n",
       "4    NaN              NaN    NaN  NaN   NaN  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "facial_expressions_columns = ['Respondent', 'Grade','Anger', 'Contempt', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise',\n",
    "       'Engagement', 'Valence', 'Sentimentality', 'Confusion', 'Neutral',\n",
    "       'Attention', 'Brow Furrow', 'Brow Raise', 'Cheek Raise', 'Chin Raise',\n",
    "       'Dimpler', 'Eye Closure', 'Eye Widen', 'Inner Brow Raise', 'Jaw Drop',\n",
    "       'Lip Corner Depressor', 'Lip Press', 'Lip Pucker', 'Lip Stretch',\n",
    "       'Lip Suck', 'Lid Tighten', 'Mouth Open', 'Nose Wrinkle', 'Smile',\n",
    "       'Smirk', 'Upper Lip Raise', 'Pitch', 'Yaw',\n",
    "       'Roll']\n",
    "# Creating a copy df with only the facial expressions data\n",
    "facial_expressions_data = combined_data_with_grades[facial_expressions_columns].copy()\n",
    "\n",
    "# Remove rows with all NaN values, except in the 'Respondent' column\n",
    "facial_expressions_data = facial_expressions_data.dropna(how='all', \n",
    "                                                         subset=facial_expressions_data.columns.difference(['Respondent']))\n",
    "\n",
    "facial_expressions_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Anger                                                         \\\n",
      "                count      mean       std  min       25%       50%       75%   \n",
      "Grade Group                                                                    \n",
      "Above 55     772163.0  1.857466  6.756095  0.0  0.139024  0.279097  1.192089   \n",
      "Below 55     164754.0  1.469313  4.383644  0.0  0.141767  0.276596  1.190347   \n",
      "\n",
      "                        Contempt            ... Sentimentality             \\\n",
      "                   max     count      mean  ...            75%        max   \n",
      "Grade Group                                 ...                             \n",
      "Above 55     97.433800  772163.0  1.751553  ...       0.386151  99.858139   \n",
      "Below 55     95.615936  164754.0  2.367286  ...       0.295878  93.977684   \n",
      "\n",
      "            Confusion                                                         \\\n",
      "                count      mean       std  min       25%       50%       75%   \n",
      "Grade Group                                                                    \n",
      "Above 55     772163.0  1.589691  6.954533  0.0  0.028905  0.123123  0.531891   \n",
      "Below 55     164754.0  2.213168  6.625465  0.0  0.130145  0.406299  1.320129   \n",
      "\n",
      "                        \n",
      "                   max  \n",
      "Grade Group             \n",
      "Above 55     99.231071  \n",
      "Below 55     94.985863  \n",
      "\n",
      "[2 rows x 88 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add a new column to the combined_data_with_grades dataframe that indicates whether the grade is above or below 55\n",
    "combined_data_with_grades['Grade Group'] = combined_data_with_grades['Grade'].apply(lambda x: 'Above 55' if x >= 55 else 'Below 55')\n",
    "\n",
    "# Describe statistics for each selected column by grade group\n",
    "selected_columns = ['Anger', 'Contempt', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise',\n",
    "       'Engagement', 'Valence', 'Sentimentality', 'Confusion']\n",
    "grouped_stats = combined_data_with_grades.groupby(['Grade Group'])[selected_columns].describe()\n",
    "\n",
    "# Print the resulting statistics dataframe\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The following 'value_vars' are not present in the DataFrame: ['Anger', 'Confusion', 'Contempt', 'Disgust', 'Engagement', 'Fear', 'Joy', 'Sadness', 'Sentimentality', 'Surprise', 'Valence']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Reshape the dataframe for visualization using a heatmap\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m grouped_stats_visual \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmelt(grouped_stats\u001b[39m.\u001b[39;49mT\u001b[39m.\u001b[39;49mreset_index(), id_vars\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mlevel_1\u001b[39;49m\u001b[39m'\u001b[39;49m], value_vars\u001b[39m=\u001b[39;49mselected_columns)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\melt.py:96\u001b[0m, in \u001b[0;36mmelt\u001b[1;34m(frame, id_vars, value_vars, var_name, value_name, col_level, ignore_index)\u001b[0m\n\u001b[0;32m     94\u001b[0m     missing \u001b[39m=\u001b[39m Index(com\u001b[39m.\u001b[39mflatten(value_vars))\u001b[39m.\u001b[39mdifference(cols)\n\u001b[0;32m     95\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing\u001b[39m.\u001b[39mempty:\n\u001b[1;32m---> 96\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[0;32m     97\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe following \u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalue_vars\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are not present in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthe DataFrame: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(missing)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m         )\n\u001b[0;32m    100\u001b[0m \u001b[39mif\u001b[39;00m col_level \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    101\u001b[0m     idx \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_level_values(col_level)\u001b[39m.\u001b[39mget_indexer(\n\u001b[0;32m    102\u001b[0m         id_vars \u001b[39m+\u001b[39m value_vars\n\u001b[0;32m    103\u001b[0m     )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"The following 'value_vars' are not present in the DataFrame: ['Anger', 'Confusion', 'Contempt', 'Disgust', 'Engagement', 'Fear', 'Joy', 'Sadness', 'Sentimentality', 'Surprise', 'Valence']\""
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Reshape the dataframe for visualization using a heatmap\n",
    "grouped_stats_visual = pd.melt(grouped_stats.T.reset_index(), id_vars=['level_1'], value_vars=selected_columns)\n",
    "grouped_stats_visual['value'] = grouped_stats_visual['value'].astype(float)\n",
    "grouped_stats_visual['variable'] = grouped_stats_visual['level_1'] + ' (' + grouped_stats_visual['Grade Group'] + ')'\n",
    "grouped_stats_visual = grouped_stats_visual[['variable', 'value']]\n",
    "grouped_stats_visual = grouped_stats_visual.pivot(index='variable', columns='Grade Group', values='value')\n",
    "\n",
    "# Create a heatmap of the statistics using seaborn\n",
    "sns.heatmap(grouped_stats_visual, cmap='coolwarm', annot=True, fmt='.2f', center=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
