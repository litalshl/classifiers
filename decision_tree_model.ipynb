{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decision Tree - Respondent 1 & 3 </h3>\n",
    "\n",
    "<h2>Pre-processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Anger  Contempt   Disgust      Fear       Joy   Sadness  Surprise  \\\n",
      "3705  0.125566  0.136948  0.021518  0.116770  0.041248  0.112264  0.059114   \n",
      "3706  0.125566  0.137617  0.021531  0.132963  0.040812  0.112249  0.067522   \n",
      "3707  0.125566  0.137096  0.021582  0.169795  0.040925  0.111568  0.087434   \n",
      "3708  0.125566  0.136868  0.021714  0.218535  0.041063  0.111219  0.114075   \n",
      "3709  0.125566  0.137239  0.021806  0.256706  0.040785  0.110944  0.135015   \n",
      "\n",
      "      Engagement  Valence  Sentimentality  Confusion Cognitive Task Screens  \n",
      "3705    0.328766      0.0        0.976782   0.036977        Explore     Map  \n",
      "3706    0.328766      0.0        0.911952   0.034095        Explore     Map  \n",
      "3707    0.328766      0.0        0.831274   0.026797        Explore     Map  \n",
      "3708    0.328766      0.0        0.829263   0.019318        Explore     Map  \n",
      "3709    0.328766      0.0        0.773583   0.014509        Explore     Map  \n",
      "148759\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '001-b45731a0_emotions_with_cognitive_tesk_and_screen.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Load the second CSV file\n",
    "new_file_path = '003-91dc3428_emotions_with_cognitive_tesk_and_screen.csv'\n",
    "new_data = pd.read_csv(new_file_path)\n",
    "\n",
    "# Merge the two dataframes\n",
    "data = pd.concat([data, new_data])\n",
    "\n",
    "# Drop the Timestamp column\n",
    "data = data.drop('Timestamp', axis=1)\n",
    "\n",
    "# Drop rows with NaN values in the target column\n",
    "data = data.dropna(subset=['Cognitive Task'])\n",
    "print(data.head())\n",
    "print(data.shape[0])\n",
    "\n",
    "# Count unique values\n",
    "# category_counts = data['Cognitive Task'].value_counts()\n",
    "\n",
    "# # Plot the Cognitive Task values distribution\n",
    "# sns.barplot(x=category_counts.index, y=category_counts.values)\n",
    "# plt.xlabel('Cognitive Task')\n",
    "# plt.ylabel('Number of Instances')\n",
    "# plt.title('Distribution of Cognitive Task Categories')\n",
    "\n",
    "# # Rotate x-axis labels by 45 degrees\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Select only relevant columns\n",
    "selected_features = ['Anger', 'Contempt', 'Disgust', 'Fear', 'Surprise', 'Confusion', 'Cognitive Task', 'Screens']\n",
    "data = data[selected_features]\n",
    "\n",
    "# Define the categories from the 'screens' column you want to include as features\n",
    "selected_screens = ['Filter', 'Supporting material', 'Map', 'Statistics']\n",
    "\n",
    "# Identify numeric and categorical features, excluding the target variable\n",
    "all_columns = data.columns.tolist()\n",
    "target_column = 'Cognitive Task'\n",
    "all_columns.remove(target_column)\n",
    "numeric_features = data[all_columns].select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = ['Screens']\n",
    "\n",
    "# Exclude the target column from the numeric features\n",
    "numeric_features = numeric_features.drop('Cognitive Task', errors='ignore')\n",
    "\n",
    "# Define the preprocessing steps for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(categories=[selected_screens], handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "# Combine the preprocessing steps into a single preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Preprocess the data\n",
    "y = data['Cognitive Task']\n",
    "X = data.drop('Cognitive Task', axis=1)\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Combine the numeric and transformed categorical feature names\n",
    "all_feature_names = list(numeric_features) + selected_screens\n",
    "\n",
    "# Convert the preprocessed data back to a DataFrame\n",
    "X_preprocessed = pd.DataFrame(X_preprocessed, columns=all_feature_names)\n",
    "\n",
    "# Reset the index of y\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Decision Tree  Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6001  315  318   48  179  510  117]\n",
      " [ 281 2113  190   48   81  239  105]\n",
      " [ 290  200 4408   52   75  161  124]\n",
      " [  58   42   58 1505   16    4  368]\n",
      " [ 196   70   90    8 1628   84   41]\n",
      " [ 534  210  192    9  103 3533    1]\n",
      " [ 112  105  118  398   43    3 4368]]\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "     Assess Results       0.80      0.80      0.80      7488\n",
      "           Conclude       0.69      0.69      0.69      3057\n",
      "            Explore       0.82      0.83      0.83      5310\n",
      "              Focus       0.73      0.73      0.73      2051\n",
      "Generate Hypothesis       0.77      0.77      0.77      2117\n",
      "           Set Goal       0.78      0.77      0.78      4582\n",
      "    Test Hypothesis       0.85      0.85      0.85      5147\n",
      "\n",
      "           accuracy                           0.79     29752\n",
      "          macro avg       0.78      0.78      0.78     29752\n",
      "       weighted avg       0.79      0.79      0.79     29752\n",
      "\n",
      "\n",
      "Accuracy Score: 0.7917450927668728\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier class\n",
    "dt = DecisionTreeClassifier(ccp_alpha=0.1)\n",
    "\n",
    "# Train the Decision Tree model\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>With Hyperparameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter search space\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [1, 2, 3, 4],\n",
    "    'ccp_alpha': [0.0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier class\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize a GridSearchCV instance to find the best hyperparameters\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Train the Decision Tree model with the best hyperparameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Check the best hyperparameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Test the model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cross Validation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.36561799360252517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use 5-fold cross-validation to evaluate the model\n",
    "cv_scores = cross_val_score(dt, X_preprocessed, y, cv=5)\n",
    "print(\"Average cross-validation score:\", np.mean(cv_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
