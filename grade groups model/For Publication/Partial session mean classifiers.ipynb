{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Partial Sessionn Classifiers</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Contempt</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>...</th>\n",
       "      <th>Fixation Dispersion</th>\n",
       "      <th>Saccade Duration</th>\n",
       "      <th>Saccade Amplitude</th>\n",
       "      <th>Saccade Peak Velocity</th>\n",
       "      <th>Saccade Peak Acceleration</th>\n",
       "      <th>Saccade Peak Deceleration</th>\n",
       "      <th>Saccade Direction</th>\n",
       "      <th>Respondent</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Grade Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36109.900</td>\n",
       "      <td>0.125566</td>\n",
       "      <td>0.186393</td>\n",
       "      <td>0.023706</td>\n",
       "      <td>0.125796</td>\n",
       "      <td>0.025453</td>\n",
       "      <td>0.125512</td>\n",
       "      <td>0.055428</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>887.4785</td>\n",
       "      <td>49.147195</td>\n",
       "      <td>385.177405</td>\n",
       "      <td>9959.550382</td>\n",
       "      <td>-7885.240429</td>\n",
       "      <td>187.258369</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>Above 55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>36269.000</td>\n",
       "      <td>0.125833</td>\n",
       "      <td>0.186909</td>\n",
       "      <td>0.023738</td>\n",
       "      <td>0.126169</td>\n",
       "      <td>0.025312</td>\n",
       "      <td>0.125694</td>\n",
       "      <td>0.055510</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>887.4785</td>\n",
       "      <td>49.147195</td>\n",
       "      <td>385.177405</td>\n",
       "      <td>9959.550382</td>\n",
       "      <td>-7885.240429</td>\n",
       "      <td>187.258369</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>Above 55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>36301.000</td>\n",
       "      <td>0.126258</td>\n",
       "      <td>0.187818</td>\n",
       "      <td>0.023798</td>\n",
       "      <td>0.126605</td>\n",
       "      <td>0.025114</td>\n",
       "      <td>0.125970</td>\n",
       "      <td>0.055607</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>887.4785</td>\n",
       "      <td>49.147195</td>\n",
       "      <td>385.177405</td>\n",
       "      <td>9959.550382</td>\n",
       "      <td>-7885.240429</td>\n",
       "      <td>187.258369</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>Above 55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>36333.000</td>\n",
       "      <td>0.126290</td>\n",
       "      <td>0.188413</td>\n",
       "      <td>0.023834</td>\n",
       "      <td>0.126583</td>\n",
       "      <td>0.024996</td>\n",
       "      <td>0.126124</td>\n",
       "      <td>0.055529</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>887.4785</td>\n",
       "      <td>49.147195</td>\n",
       "      <td>385.177405</td>\n",
       "      <td>9959.550382</td>\n",
       "      <td>-7885.240429</td>\n",
       "      <td>187.258369</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>Above 55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>36371.192</td>\n",
       "      <td>0.126344</td>\n",
       "      <td>0.188792</td>\n",
       "      <td>0.023866</td>\n",
       "      <td>0.126641</td>\n",
       "      <td>0.024909</td>\n",
       "      <td>0.126202</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>887.4785</td>\n",
       "      <td>49.147195</td>\n",
       "      <td>385.177405</td>\n",
       "      <td>9959.550382</td>\n",
       "      <td>-7885.240429</td>\n",
       "      <td>187.258369</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>Above 55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  Timestamp     Anger  Contempt   Disgust  \\\n",
       "0             0           1  36109.900  0.125566  0.186393  0.023706   \n",
       "1             1           3  36269.000  0.125833  0.186909  0.023738   \n",
       "2             2           5  36301.000  0.126258  0.187818  0.023798   \n",
       "3             3           7  36333.000  0.126290  0.188413  0.023834   \n",
       "4             4           9  36371.192  0.126344  0.188792  0.023866   \n",
       "\n",
       "       Fear       Joy   Sadness  Surprise  ...  Fixation Dispersion  \\\n",
       "0  0.125796  0.025453  0.125512  0.055428  ...                  NaN   \n",
       "1  0.126169  0.025312  0.125694  0.055510  ...                  NaN   \n",
       "2  0.126605  0.025114  0.125970  0.055607  ...                  NaN   \n",
       "3  0.126583  0.024996  0.126124  0.055529  ...                  NaN   \n",
       "4  0.126641  0.024909  0.126202  0.055519  ...                  NaN   \n",
       "\n",
       "   Saccade Duration  Saccade Amplitude  Saccade Peak Velocity  \\\n",
       "0          887.4785          49.147195             385.177405   \n",
       "1          887.4785          49.147195             385.177405   \n",
       "2          887.4785          49.147195             385.177405   \n",
       "3          887.4785          49.147195             385.177405   \n",
       "4          887.4785          49.147195             385.177405   \n",
       "\n",
       "   Saccade Peak Acceleration  Saccade Peak Deceleration  Saccade Direction  \\\n",
       "0                9959.550382               -7885.240429         187.258369   \n",
       "1                9959.550382               -7885.240429         187.258369   \n",
       "2                9959.550382               -7885.240429         187.258369   \n",
       "3                9959.550382               -7885.240429         187.258369   \n",
       "4                9959.550382               -7885.240429         187.258369   \n",
       "\n",
       "   Respondent  Grade  Grade Group  \n",
       "0           1    100     Above 55  \n",
       "1           1    100     Above 55  \n",
       "2           1    100     Above 55  \n",
       "3           1    100     Above 55  \n",
       "4           1    100     Above 55  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "file_path = './datasets/merged_data_march_9_2024.csv'\n",
    "merged_data_from_file = df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "merged_data_from_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mean values for size 2000 to 'mean_values_2000_samples.csv'\n",
      "Saved mean values for size 5000 to 'mean_values_5000_samples.csv'\n",
      "Saved mean values for size 10000 to 'mean_values_10000_samples.csv'\n",
      "Saved mean values for size 15000 to 'mean_values_15000_samples.csv'\n",
      "Saved mean values for size 20000 to 'mean_values_20000_samples.csv'\n",
      "Saved mean values for size 30000 to 'mean_values_30000_samples.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample sizes for which you want to calculate means\n",
    "sample_sizes = [2000, 5000, 10000, 15000, 20000, 30000]\n",
    "\n",
    "columns_to_average = ['Anger', 'Contempt',\n",
    "       'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Engagement',\n",
    "       'Sentimentality', 'Confusion',\n",
    "       'Brow Furrow', 'Brow Raise', 'Cheek Raise', 'Chin Raise', 'Dimpler',\n",
    "       'Eye Closure', 'Eye Widen', 'Inner Brow Raise', 'Jaw Drop',\n",
    "       'Lip Corner Depressor', 'Lip Press', 'Lip Pucker', 'Lip Stretch',\n",
    "       'Lip Suck', 'Lid Tighten', 'Mouth Open', 'Nose Wrinkle', 'Smile',\n",
    "       'Smirk', 'Upper Lip Raise', 'Blink', 'BlinkRate', 'Grade'] \n",
    "\n",
    "# List to hold the resulting DataFrames\n",
    "mean_dfs = []\n",
    "\n",
    "for size in sample_sizes:\n",
    "    # Temporary list to hold the mean data for each respondent for the current size\n",
    "    temp_mean_list = []\n",
    "    \n",
    "    # Iterate over each group of respondents\n",
    "    for name, group in merged_data_from_file.groupby('Respondent'):\n",
    "        # Ensure the group is sorted by timestamp\n",
    "        sorted_group = group.sort_values(by='Timestamp')\n",
    "        \n",
    "        # Select the first 'size' samples\n",
    "        selected_samples = sorted_group.head(size)\n",
    "        \n",
    "        # Calculate mean for the selected portion, for the specified columns\n",
    "        mean_values = selected_samples[columns_to_average].mean().to_frame().T\n",
    "        \n",
    "        # Adding back the 'Respondent' information\n",
    "        mean_values['Respondent'] = name\n",
    "        \n",
    "        # Append to the temporary list\n",
    "        temp_mean_list.append(mean_values)\n",
    "    \n",
    "    # Concatenate all the mean values for the current sample size into a single DataFrame\n",
    "    mean_df_for_current_size = pd.concat(temp_mean_list, ignore_index=True)\n",
    "    \n",
    "    # Save this DataFrame to a CSV file, including the size in the file name\n",
    "    filename = f\"mean_values_{size}_samples.csv\"\n",
    "    mean_df_for_current_size.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Saved mean values for size {size} to '{filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mean Values per Respondent</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anger</th>\n",
       "      <th>Contempt</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Engagement</th>\n",
       "      <th>Sentimentality</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>...</th>\n",
       "      <th>Lid Tighten</th>\n",
       "      <th>Mouth Open</th>\n",
       "      <th>Nose Wrinkle</th>\n",
       "      <th>Smile</th>\n",
       "      <th>Smirk</th>\n",
       "      <th>Upper Lip Raise</th>\n",
       "      <th>Blink</th>\n",
       "      <th>BlinkRate</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Respondent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.460075</td>\n",
       "      <td>0.491092</td>\n",
       "      <td>0.615946</td>\n",
       "      <td>1.671355</td>\n",
       "      <td>12.726885</td>\n",
       "      <td>0.130559</td>\n",
       "      <td>0.787589</td>\n",
       "      <td>34.276376</td>\n",
       "      <td>2.791451</td>\n",
       "      <td>0.286980</td>\n",
       "      <td>...</td>\n",
       "      <td>2.004562</td>\n",
       "      <td>39.148101</td>\n",
       "      <td>1.124512</td>\n",
       "      <td>17.116794</td>\n",
       "      <td>0.788075</td>\n",
       "      <td>4.155210</td>\n",
       "      <td>0.015158</td>\n",
       "      <td>27.466193</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.657339</td>\n",
       "      <td>2.497986</td>\n",
       "      <td>0.505919</td>\n",
       "      <td>1.337851</td>\n",
       "      <td>0.667771</td>\n",
       "      <td>0.490273</td>\n",
       "      <td>1.320833</td>\n",
       "      <td>37.006478</td>\n",
       "      <td>0.940148</td>\n",
       "      <td>1.302159</td>\n",
       "      <td>...</td>\n",
       "      <td>1.479863</td>\n",
       "      <td>52.329280</td>\n",
       "      <td>0.225366</td>\n",
       "      <td>0.801355</td>\n",
       "      <td>2.994338</td>\n",
       "      <td>0.668531</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>15.758642</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.198353</td>\n",
       "      <td>0.178260</td>\n",
       "      <td>0.230945</td>\n",
       "      <td>1.683921</td>\n",
       "      <td>3.465970</td>\n",
       "      <td>0.122122</td>\n",
       "      <td>2.781056</td>\n",
       "      <td>26.920676</td>\n",
       "      <td>0.636366</td>\n",
       "      <td>0.092490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112332</td>\n",
       "      <td>39.307218</td>\n",
       "      <td>0.040999</td>\n",
       "      <td>4.848062</td>\n",
       "      <td>0.809057</td>\n",
       "      <td>0.538774</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>4.726374</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.051855</td>\n",
       "      <td>2.754203</td>\n",
       "      <td>0.546304</td>\n",
       "      <td>0.658555</td>\n",
       "      <td>3.155066</td>\n",
       "      <td>0.168415</td>\n",
       "      <td>0.162380</td>\n",
       "      <td>43.138427</td>\n",
       "      <td>0.929626</td>\n",
       "      <td>0.260626</td>\n",
       "      <td>...</td>\n",
       "      <td>3.089902</td>\n",
       "      <td>64.136455</td>\n",
       "      <td>0.424273</td>\n",
       "      <td>3.628829</td>\n",
       "      <td>5.230358</td>\n",
       "      <td>1.227411</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>19.058286</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330839</td>\n",
       "      <td>3.555499</td>\n",
       "      <td>0.090615</td>\n",
       "      <td>0.190665</td>\n",
       "      <td>2.169144</td>\n",
       "      <td>2.234976</td>\n",
       "      <td>0.066392</td>\n",
       "      <td>12.771172</td>\n",
       "      <td>2.278678</td>\n",
       "      <td>2.179642</td>\n",
       "      <td>...</td>\n",
       "      <td>2.051791</td>\n",
       "      <td>4.730730</td>\n",
       "      <td>0.643221</td>\n",
       "      <td>4.315888</td>\n",
       "      <td>10.901762</td>\n",
       "      <td>1.381639</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>16.343505</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Anger  Contempt   Disgust      Fear        Joy   Sadness  Surprise  \\\n",
       "0  1.460075  0.491092  0.615946  1.671355  12.726885  0.130559  0.787589   \n",
       "1  1.657339  2.497986  0.505919  1.337851   0.667771  0.490273  1.320833   \n",
       "2  1.198353  0.178260  0.230945  1.683921   3.465970  0.122122  2.781056   \n",
       "3  1.051855  2.754203  0.546304  0.658555   3.155066  0.168415  0.162380   \n",
       "4  0.330839  3.555499  0.090615  0.190665   2.169144  2.234976  0.066392   \n",
       "\n",
       "   Engagement  Sentimentality  Confusion  ...  Lid Tighten  Mouth Open  \\\n",
       "0   34.276376        2.791451   0.286980  ...     2.004562   39.148101   \n",
       "1   37.006478        0.940148   1.302159  ...     1.479863   52.329280   \n",
       "2   26.920676        0.636366   0.092490  ...     0.112332   39.307218   \n",
       "3   43.138427        0.929626   0.260626  ...     3.089902   64.136455   \n",
       "4   12.771172        2.278678   2.179642  ...     2.051791    4.730730   \n",
       "\n",
       "   Nose Wrinkle      Smile      Smirk  Upper Lip Raise     Blink  BlinkRate  \\\n",
       "0      1.124512  17.116794   0.788075         4.155210  0.015158  27.466193   \n",
       "1      0.225366   0.801355   2.994338         0.668531  0.006800  15.758642   \n",
       "2      0.040999   4.848062   0.809057         0.538774  0.002600   4.726374   \n",
       "3      0.424273   3.628829   5.230358         1.227411  0.010600  19.058286   \n",
       "4      0.643221   4.315888  10.901762         1.381639  0.008800  16.343505   \n",
       "\n",
       "   Grade  Respondent  \n",
       "0  100.0           1  \n",
       "1   50.0           2  \n",
       "2   55.0           3  \n",
       "3   75.0           4  \n",
       "4   65.0           5  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "file_path = './datasets/mean_values_10000_samples.csv'\n",
    "mean_data_from_file = df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "mean_data_from_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to the combined_data_with_grades dataframe that indicates whether the grade is above or below 55\n",
    "mean_data_from_file['Grade Group'] = mean_data_from_file['Grade'].apply(lambda x: 'Above 55' if x > 55 else 'Below 55')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classifiers</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Logistic Regression</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [0.66666667 0.66666667 1.         1.         0.5        0.5\n",
      " 0.5       ]\n",
      "Mean cross-validation accuracy: 0.6904761904761905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Separating features and target variable\n",
    "X = mean_data_from_file[[ 'Contempt', 'Smirk', 'Surprise', 'Joy', 'Smile', 'Sadness', 'BlinkRate']]  \n",
    "y = mean_data_from_file['Grade Group'] \n",
    "\n",
    "# Splitting the dataset into the Training set and Hold-out Validation set\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "# Creating a logistic regression model pipeline with standard scaling\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logisticregression', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Training the model on the entire Training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Hold-out Validation set results\n",
    "y_pred = model.predict(X_validation)\n",
    "\n",
    "\n",
    "# Define Stratified K-Fold cross-validator\n",
    "# To approximate a 70/30 split, you can use about 3 folds (since 1/3 is approximately 0.33, close to 30%)\n",
    "skf = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and calculate accuracy\n",
    "# Note: You might want to use scoring='accuracy' or another relevant metric based on your problem\n",
    "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy scores for each fold: {scores}\")\n",
    "print(f\"Mean cross-validation accuracy: {np.mean(scores)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest for Grade Group</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [0.66666667 1.         1.         1.         1.         1.\n",
      " 0.5       ]\n",
      "Mean cross-validation accuracy: 0.8809523809523808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# List of columns to use as features\n",
    "features_list = ['Contempt', 'Smirk', 'Surprise', 'Joy', 'Smile', 'Sadness', 'BlinkRate']\n",
    "\n",
    "# Selecting the features and target from the DataFrame\n",
    "X = mean_data_from_file[features_list]\n",
    "y = mean_data_from_file['Grade Group']  # Assuming 'Grade Group' is your target variable for classification\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestClassifier directly\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the RandomForestClassifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Define Stratified K-Fold cross-validator\n",
    "# To approximate a 70/30 split, you can use about 3 folds (since 1/3 is approximately 0.33, close to 30%)\n",
    "skf = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and calculate accuracy\n",
    "# Note: You might want to use scoring='accuracy' or another relevant metric based on your problem\n",
    "scores = cross_val_score(rf_classifier, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy scores for each fold: {scores}\")\n",
    "print(f\"Mean cross-validation accuracy: {np.mean(scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_first_5_minutes_classifier.joblib']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Save the model to file\n",
    "dump(rf_classifier, 'rf_first_5_minutes_classifier.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decision Tree Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [0.66666667 0.         1.         0.5        0.5        0.5\n",
      " 0.5       ]\n",
      "Mean cross-validation accuracy: 0.5238095238095238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# List of columns to use as features\n",
    "features_list = ['Contempt', 'Smirk', 'Surprise', 'Joy', 'Smile', 'Sadness', 'BlinkRate']\n",
    "\n",
    "# Selecting the features and target from the DataFrame\n",
    "X = mean_data_from_file[features_list]\n",
    "y = mean_data_from_file['Grade Group']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "\n",
    "# Initialize the model directly with DecisionTreeClassifier, without StandardScaler\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(dt_classifier, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy scores for each fold: {scores}\")\n",
    "print(f\"Mean cross-validation accuracy: {np.mean(scores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Naive Bayes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [0.  0.  0.5 1.  0.5 1.  0.5]\n",
      "Mean cross-validation accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# List of columns to use as features\n",
    "features_list = [ 'Smirk', 'Surprise', 'Joy', 'Smile', 'Sadness', 'BlinkRate']\n",
    "\n",
    "# Selecting the features and target from the DataFrame\n",
    "X = mean_data_from_file[features_list]\n",
    "y = mean_data_from_file['Grade Group']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initializing the Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Fitting the model on the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "\n",
    "scores = cross_val_score(gnb, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy scores for each fold: {scores}\")\n",
    "print(f\"Mean cross-validation accuracy: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>XGBoost</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category 'Above 55' is encoded as 0.\n",
      "The category 'Below 55' is encoded as 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [0.66666667 1.         1.         0.5        0.5        0.5\n",
      " 0.5       ]\n",
      "Mean cross-validation accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Assuming mean_data_from_file is your DataFrame, and it's already defined\n",
    "features_list = ['Contempt', 'Surprise', 'Joy', 'Sadness']\n",
    "\n",
    "X = mean_data_from_file[features_list]\n",
    "y = mean_data_from_file['Grade Group']  # Target variable for classification\n",
    "\n",
    "# Encoding string labels to numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# To find out which category is encoded as 0 (or any other number)\n",
    "encoded_labels = list(label_encoder.classes_)\n",
    "for index, label in enumerate(encoded_labels):\n",
    "    print(f\"The category '{label}' is encoded as {index}.\")\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize XGBClassifier without use_label_encoder\n",
    "xgb_classifier = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# Fit the XGBClassifier on the training data\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgb_classifier, X, y_encoded, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy scores for each fold: {scores}\")\n",
    "print(f\"Mean cross-validation accuracy: {np.mean(scores)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
