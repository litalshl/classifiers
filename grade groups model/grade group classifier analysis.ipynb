{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Analysis of the Grade Group Random Forest Model</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Test Dataset of First 6 Seconds From All Respondents</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Anger  Contempt   Disgust      Fear       Joy   Sadness  Surprise  \\\n",
      "5   0.125566  0.186393  0.023706  0.125796  0.025453  0.125512  0.055428   \n",
      "7   0.125833  0.186909  0.023738  0.126169  0.025312  0.125694  0.055510   \n",
      "9   0.126258  0.187818  0.023798  0.126605  0.025114  0.125970  0.055607   \n",
      "11  0.126290  0.188413  0.023834  0.126583  0.024996  0.126124  0.055529   \n",
      "13  0.126344  0.188792  0.023866  0.126641  0.024909  0.126202  0.055519   \n",
      "\n",
      "    Engagement  Valence  Sentimentality  Confusion  \n",
      "5     0.328766      0.0        0.030948   0.004428  \n",
      "7     0.328766      0.0        0.051102   0.007234  \n",
      "9     0.328766      0.0        0.043316   0.012638  \n",
      "11    0.328766      0.0        0.032416   0.013319  \n",
      "13    0.328766      0.0        0.028298   0.013363  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_path = \"../all respondents data/\"\n",
    "\n",
    "# Select the columns to include in the dataset\n",
    "selected_columns = ['Anger', 'Contempt', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise',\n",
    "       'Engagement', 'Valence', 'Sentimentality', 'Confusion']\n",
    "\n",
    "csv_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "data_list = []\n",
    "for file in csv_files:\n",
    "    data = pd.read_csv(file, header=0, usecols=selected_columns, nrows=250).dropna()\n",
    "    data_list.append(data)\n",
    "\n",
    "df = pd.concat(data_list)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Anger   Contempt   Disgust      Fear       Joy   Sadness  Surprise  \\\n",
      "5    0.125566   0.186393  0.023706  0.125796  0.025453  0.125512  0.055428   \n",
      "7    0.125833   0.186909  0.023738  0.126169  0.025312  0.125694  0.055510   \n",
      "9    0.126258   0.187818  0.023798  0.126605  0.025114  0.125970  0.055607   \n",
      "11   0.126290   0.188413  0.023834  0.126583  0.024996  0.126124  0.055529   \n",
      "13   0.126344   0.188792  0.023866  0.126641  0.024909  0.126202  0.055519   \n",
      "..        ...        ...       ...       ...       ...       ...       ...   \n",
      "190  0.813891  10.912367  0.178709  0.650948  0.029256  0.264468  0.281056   \n",
      "192  0.762514  47.368874  0.144964  0.558924  0.031119  0.302397  0.264432   \n",
      "194  0.834973  78.164200  0.118704  0.457550  0.033249  0.316273  0.216130   \n",
      "196  1.234668  91.640717  0.089462  0.533636  0.036385  0.294732  0.239699   \n",
      "198  1.476485  95.016411  0.073928  0.601103  0.038038  0.268923  0.243317   \n",
      "\n",
      "     Engagement   Valence  Sentimentality  Confusion Respondent  \n",
      "5      0.328766  0.000000        0.030948   0.004428        001  \n",
      "7      0.328766  0.000000        0.051102   0.007234        001  \n",
      "9      0.328766  0.000000        0.043316   0.012638        001  \n",
      "11     0.328766  0.000000        0.032416   0.013319        001  \n",
      "13     0.328766  0.000000        0.028298   0.013363        001  \n",
      "..          ...       ...             ...        ...        ...  \n",
      "190    1.055922  0.000000        2.675263   0.108685        019  \n",
      "192    1.779390  0.000000        3.490416   0.087332        019  \n",
      "194    8.453645 -1.823975        4.254953   0.069634        019  \n",
      "196   27.625784 -5.807800        5.352370   0.056684        019  \n",
      "198   46.476891 -7.181229        5.517698   0.051588        019  \n",
      "\n",
      "[2309 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder path where the CSV files are located\n",
    "folder_path = \"../all respondents data\"\n",
    "\n",
    "# Initialize an empty dataframe to store the combined data\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Select the columns to include in the dataset\n",
    "selected_columns = ['Anger', 'Contempt', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise',\n",
    "       'Engagement', 'Valence', 'Sentimentality', 'Confusion']\n",
    "\n",
    "# Loop through each file in the folder with .csv extension and append to the combined_data dataframe\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path, header=0, usecols=selected_columns, low_memory=False, nrows=200).dropna()\n",
    "        respondent_num = filename.split('_')[0]  # Get the first part of the filename before the first '_'\n",
    "        df['Respondent'] = respondent_num  # Add a new column with the respondent number\n",
    "        combined_data = pd.concat([combined_data, df])\n",
    "\n",
    "# Print the combined data\n",
    "print(combined_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Add Grades to the Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Anger   Contempt   Disgust      Fear       Joy   Sadness  Surprise  \\\n",
      "0     0.125566   0.186393  0.023706  0.125796  0.025453  0.125512  0.055428   \n",
      "1     0.125833   0.186909  0.023738  0.126169  0.025312  0.125694  0.055510   \n",
      "2     0.126258   0.187818  0.023798  0.126605  0.025114  0.125970  0.055607   \n",
      "3     0.126290   0.188413  0.023834  0.126583  0.024996  0.126124  0.055529   \n",
      "4     0.126344   0.188792  0.023866  0.126641  0.024909  0.126202  0.055519   \n",
      "...        ...        ...       ...       ...       ...       ...       ...   \n",
      "2105  0.813891  10.912367  0.178709  0.650948  0.029256  0.264468  0.281056   \n",
      "2106  0.762514  47.368874  0.144964  0.558924  0.031119  0.302397  0.264432   \n",
      "2107  0.834973  78.164200  0.118704  0.457550  0.033249  0.316273  0.216130   \n",
      "2108  1.234668  91.640717  0.089462  0.533636  0.036385  0.294732  0.239699   \n",
      "2109  1.476485  95.016411  0.073928  0.601103  0.038038  0.268923  0.243317   \n",
      "\n",
      "      Engagement   Valence  Sentimentality  Confusion Respondent  Grade  \n",
      "0       0.328766  0.000000        0.030948   0.004428        001    100  \n",
      "1       0.328766  0.000000        0.051102   0.007234        001    100  \n",
      "2       0.328766  0.000000        0.043316   0.012638        001    100  \n",
      "3       0.328766  0.000000        0.032416   0.013319        001    100  \n",
      "4       0.328766  0.000000        0.028298   0.013363        001    100  \n",
      "...          ...       ...             ...        ...        ...    ...  \n",
      "2105    1.055922  0.000000        2.675263   0.108685        019     55  \n",
      "2106    1.779390  0.000000        3.490416   0.087332        019     55  \n",
      "2107    8.453645 -1.823975        4.254953   0.069634        019     55  \n",
      "2108   27.625784 -5.807800        5.352370   0.056684        019     55  \n",
      "2109   46.476891 -7.181229        5.517698   0.051588        019     55  \n",
      "\n",
      "[2110 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in the Grades.csv file\n",
    "grades_df = pd.read_csv('Grades.csv')\n",
    "\n",
    "# Remove the trailing underscore from the \"Respondent\" column in the grades_df dataframe\n",
    "grades_df['Respondent'] = grades_df['Respondent'].str.rstrip('_')\n",
    "\n",
    "# Merge the combined_data and grades_df dataframes based on the \"Respondent\" column\n",
    "combined_data_with_grades = pd.merge(combined_data, grades_df[['Respondent', 'Grade']], on='Respondent')\n",
    "\n",
    "# Print the resulting dataframe with the added \"Grade\" column\n",
    "print(combined_data_with_grades)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Add Grade Group Column</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Anger   Contempt   Disgust      Fear       Joy   Sadness  Surprise  \\\n",
      "0     0.125566   0.186393  0.023706  0.125796  0.025453  0.125512  0.055428   \n",
      "1     0.125833   0.186909  0.023738  0.126169  0.025312  0.125694  0.055510   \n",
      "2     0.126258   0.187818  0.023798  0.126605  0.025114  0.125970  0.055607   \n",
      "3     0.126290   0.188413  0.023834  0.126583  0.024996  0.126124  0.055529   \n",
      "4     0.126344   0.188792  0.023866  0.126641  0.024909  0.126202  0.055519   \n",
      "...        ...        ...       ...       ...       ...       ...       ...   \n",
      "2105  0.813891  10.912367  0.178709  0.650948  0.029256  0.264468  0.281056   \n",
      "2106  0.762514  47.368874  0.144964  0.558924  0.031119  0.302397  0.264432   \n",
      "2107  0.834973  78.164200  0.118704  0.457550  0.033249  0.316273  0.216130   \n",
      "2108  1.234668  91.640717  0.089462  0.533636  0.036385  0.294732  0.239699   \n",
      "2109  1.476485  95.016411  0.073928  0.601103  0.038038  0.268923  0.243317   \n",
      "\n",
      "      Engagement   Valence  Sentimentality  Confusion Respondent  Grade  \\\n",
      "0       0.328766  0.000000        0.030948   0.004428        001    100   \n",
      "1       0.328766  0.000000        0.051102   0.007234        001    100   \n",
      "2       0.328766  0.000000        0.043316   0.012638        001    100   \n",
      "3       0.328766  0.000000        0.032416   0.013319        001    100   \n",
      "4       0.328766  0.000000        0.028298   0.013363        001    100   \n",
      "...          ...       ...             ...        ...        ...    ...   \n",
      "2105    1.055922  0.000000        2.675263   0.108685        019     55   \n",
      "2106    1.779390  0.000000        3.490416   0.087332        019     55   \n",
      "2107    8.453645 -1.823975        4.254953   0.069634        019     55   \n",
      "2108   27.625784 -5.807800        5.352370   0.056684        019     55   \n",
      "2109   46.476891 -7.181229        5.517698   0.051588        019     55   \n",
      "\n",
      "     Grade Group  \n",
      "0       Above 55  \n",
      "1       Above 55  \n",
      "2       Above 55  \n",
      "3       Above 55  \n",
      "4       Above 55  \n",
      "...          ...  \n",
      "2105    Below 55  \n",
      "2106    Below 55  \n",
      "2107    Below 55  \n",
      "2108    Below 55  \n",
      "2109    Below 55  \n",
      "\n",
      "[2110 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column to the combined_data_with_grades dataframe that indicates whether the grade is above or below 55\n",
    "combined_data_with_grades['Grade Group'] = combined_data_with_grades['Grade'].apply(lambda x: 'Above 55' if x > 55 else 'Below 55')\n",
    "\n",
    "print(combined_data_with_grades)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Run Prediction on the Dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on new data: 0.8559241706161137\n",
      "Accuracy score: 0.8559241706161137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Above 55       0.85      0.87      0.86      1102\n",
      "    Below 55       0.86      0.84      0.85      1008\n",
      "\n",
      "    accuracy                           0.86      2110\n",
      "   macro avg       0.86      0.86      0.86      2110\n",
      "weighted avg       0.86      0.86      0.86      2110\n",
      "\n",
      "Confusion matrix:\n",
      "[[962 140]\n",
      " [164 844]]\n",
      "FPR:  0.12704174228675136\n",
      "TPR:  0.8373015873015873\n",
      "FNR:  0.1626984126984127\n",
      "TNR:  0.8729582577132486\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, confusion_matrix, classification_report\n",
    "\n",
    "# Load the saved model from the pickle file\n",
    "with open(f'random_forest_classifier_2023-05-08_21-14-34.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Extract the features from the full data\n",
    "features = combined_data_with_grades[selected_columns]\n",
    "\n",
    "# Make predictions on the features using the loaded model\n",
    "predictions = model.predict(features)\n",
    "\n",
    "# Compare the predicted grade group labels with the pre-labeled grade group labels\n",
    "correct_predictions = sum(predictions == combined_data_with_grades['Grade Group']) \n",
    "accuracy = correct_predictions / len(combined_data_with_grades)\n",
    "print(f\"Accuracy on new data: {accuracy}\")\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy score:\", accuracy_score(combined_data_with_grades['Grade Group'], predictions))\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(combined_data_with_grades['Grade Group'], predictions))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(combined_data_with_grades['Grade Group'], predictions))\n",
    "\n",
    "# Evaluate the model\n",
    "tn, fp, fn, tp = confusion_matrix(combined_data_with_grades['Grade Group'], predictions).ravel()\n",
    "\n",
    "# Calculate TPR, FPR, TNR, FNR\n",
    "tnr = tn / (tn + fp)\n",
    "tpr = tp / (tp + fn)\n",
    "fnr = fn / (fn + tp)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print('FPR: ', fpr)\n",
    "print('TPR: ', tpr)\n",
    "print('FNR: ', fnr)\n",
    "print('TNR: ', tnr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
