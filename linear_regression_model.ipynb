{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Linear Regression - Respondent 1 & 3 </h3>\n",
    "\n",
    "<h2>Pre-processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Anger  Contempt   Disgust      Fear       Joy   Sadness  Surprise  \\\n",
      "3705  0.125566  0.136948  0.021518  0.116770  0.041248  0.112264  0.059114   \n",
      "3706  0.125566  0.137617  0.021531  0.132963  0.040812  0.112249  0.067522   \n",
      "3707  0.125566  0.137096  0.021582  0.169795  0.040925  0.111568  0.087434   \n",
      "3708  0.125566  0.136868  0.021714  0.218535  0.041063  0.111219  0.114075   \n",
      "3709  0.125566  0.137239  0.021806  0.256706  0.040785  0.110944  0.135015   \n",
      "\n",
      "      Engagement  Valence  Sentimentality  Confusion Cognitive Task Screens  \n",
      "3705    0.328766      0.0        0.976782   0.036977        Explore     Map  \n",
      "3706    0.328766      0.0        0.911952   0.034095        Explore     Map  \n",
      "3707    0.328766      0.0        0.831274   0.026797        Explore     Map  \n",
      "3708    0.328766      0.0        0.829263   0.019318        Explore     Map  \n",
      "3709    0.328766      0.0        0.773583   0.014509        Explore     Map  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '001-b45731a0_emotions_with_cognitive_tesk_and_screen.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Load the second CSV file\n",
    "new_file_path = '003-91dc3428_emotions_with_cognitive_tesk_and_screen.csv'\n",
    "new_data = pd.read_csv(new_file_path)\n",
    "\n",
    "# Merge the two dataframes\n",
    "data = pd.concat([data, new_data])\n",
    "\n",
    "# Drop the Timestamp column\n",
    "data = data.drop('Timestamp', axis=1)\n",
    "\n",
    "# Drop rows with NaN values in the target column\n",
    "data = data.dropna(subset=['Cognitive Task'])\n",
    "print(data.head())\n",
    "\n",
    "# Select only relevant columns\n",
    "selected_features = ['Anger', 'Contempt', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Confusion', 'Cognitive Task', 'Screens']\n",
    "data = data[selected_features]\n",
    "\n",
    "# Define the categories from the 'screens' column you want to include as features\n",
    "selected_screens = ['Filter', 'Supporting material', 'Map', 'Statistics']\n",
    "\n",
    "# Identify numeric and categorical features, excluding the target variable\n",
    "all_columns = data.columns.tolist()\n",
    "target_column = 'Cognitive Task'\n",
    "all_columns.remove(target_column)\n",
    "numeric_features = data[all_columns].select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = ['Screens']\n",
    "\n",
    "# Exclude the target column from the numeric features\n",
    "numeric_features = numeric_features.drop('Cognitive Task', errors='ignore')\n",
    "\n",
    "# Define the preprocessing steps for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(categories=[selected_screens], handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "# Combine the preprocessing steps into a single preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Preprocess the data\n",
    "y = data['Cognitive Task']\n",
    "X = data.drop('Cognitive Task', axis=1)\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Combine the numeric and transformed categorical feature names\n",
    "all_feature_names = list(numeric_features) + selected_screens\n",
    "\n",
    "# Convert the preprocessed data back to a DataFrame\n",
    "X_preprocessed = pd.DataFrame(X_preprocessed, columns=all_feature_names)\n",
    "\n",
    "# Reset the index of y\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Linear Regression Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Focus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m# Train the Linear Regression model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m lin_reg \u001b[39m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 11\u001b[0m lin_reg\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Test the model\u001b[39;00m\n\u001b[0;32m     14\u001b[0m y_pred \u001b[39m=\u001b[39m lin_reg\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    649\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m )\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype, only_non_negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[1;32m-> 1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric, estimator\u001b[39m=\u001b[39;49mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1126\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     _ensure_no_complex_data(y)\n\u001b[0;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m y_numeric \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1147\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat64)\n\u001b[0;32m   1149\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Focus'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Train the Linear Regression model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Evaluate the model's performance using metrics like mean squared error (MSE) and R² score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error: {:.2f}\".format(mse))\n",
    "print(\"R² Score: {:.2f}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use 5-fold cross-validation to evaluate the model\n",
    "cv_scores = cross_val_score(model, X_preprocessed, y, cv=5)\n",
    "print(\"Average cross-validation score:\", np.mean(cv_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
