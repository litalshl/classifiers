{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decision Tree - Respondent 1 & 3 </h3>\n",
    "\n",
    "<h2>Pre-processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Anger  Contempt   Disgust      Fear       Joy   Sadness  Surprise  \\\n",
      "3705  0.125566  0.136948  0.021518  0.116770  0.041248  0.112264  0.059114   \n",
      "3706  0.125566  0.137617  0.021531  0.132963  0.040812  0.112249  0.067522   \n",
      "3707  0.125566  0.137096  0.021582  0.169795  0.040925  0.111568  0.087434   \n",
      "3708  0.125566  0.136868  0.021714  0.218535  0.041063  0.111219  0.114075   \n",
      "3709  0.125566  0.137239  0.021806  0.256706  0.040785  0.110944  0.135015   \n",
      "\n",
      "      Engagement  Valence  Sentimentality  Confusion Cognitive Task Screens  \n",
      "3705    0.328766      0.0        0.976782   0.036977        Explore     Map  \n",
      "3706    0.328766      0.0        0.911952   0.034095        Explore     Map  \n",
      "3707    0.328766      0.0        0.831274   0.026797        Explore     Map  \n",
      "3708    0.328766      0.0        0.829263   0.019318        Explore     Map  \n",
      "3709    0.328766      0.0        0.773583   0.014509        Explore     Map  \n",
      "148759\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '001-b45731a0_emotions_with_cognitive_tesk_and_screen.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Load the second CSV file\n",
    "new_file_path = '003-91dc3428_emotions_with_cognitive_tesk_and_screen.csv'\n",
    "new_data = pd.read_csv(new_file_path)\n",
    "\n",
    "# Merge the two dataframes\n",
    "data = pd.concat([data, new_data])\n",
    "\n",
    "# Drop the Timestamp column\n",
    "data = data.drop('Timestamp', axis=1)\n",
    "\n",
    "# Drop rows with NaN values in the target column\n",
    "data = data.dropna(subset=['Cognitive Task'])\n",
    "print(data.head())\n",
    "print(data.shape[0])\n",
    "\n",
    "# Count unique values\n",
    "# category_counts = data['Cognitive Task'].value_counts()\n",
    "\n",
    "# # Plot the Cognitive Task values distribution\n",
    "# sns.barplot(x=category_counts.index, y=category_counts.values)\n",
    "# plt.xlabel('Cognitive Task')\n",
    "# plt.ylabel('Number of Instances')\n",
    "# plt.title('Distribution of Cognitive Task Categories')\n",
    "\n",
    "# # Rotate x-axis labels by 45 degrees\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Select only relevant columns\n",
    "selected_features = ['Anger', 'Fear', 'Surprise', 'Confusion', 'Cognitive Task', 'Screens']\n",
    "data = data[selected_features]\n",
    "\n",
    "# Define the categories from the 'screens' column you want to include as features\n",
    "selected_screens = ['Filter', 'Statistics']\n",
    "\n",
    "# Identify numeric and categorical features, excluding the target variable\n",
    "all_columns = data.columns.tolist()\n",
    "target_column = 'Cognitive Task'\n",
    "all_columns.remove(target_column)\n",
    "numeric_features = data[all_columns].select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = ['Screens']\n",
    "\n",
    "# Exclude the target column from the numeric features\n",
    "numeric_features = numeric_features.drop('Cognitive Task', errors='ignore')\n",
    "\n",
    "# Define the preprocessing steps for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(categories=[selected_screens], handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "# Combine the preprocessing steps into a single preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Preprocess the data\n",
    "y = data['Cognitive Task']\n",
    "X = data.drop('Cognitive Task', axis=1)\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Combine the numeric and transformed categorical feature names\n",
    "all_feature_names = list(numeric_features) + selected_screens\n",
    "\n",
    "# Convert the preprocessed data back to a DataFrame\n",
    "X_preprocessed = pd.DataFrame(X_preprocessed, columns=all_feature_names)\n",
    "\n",
    "# Reset the index of y\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Decision Tree  Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6024  304  316   53  173  505  113]\n",
      " [ 277 2111  206   46   89  228  100]\n",
      " [ 283  203 4419   57   75  148  125]\n",
      " [  64   40   53 1512   14    4  364]\n",
      " [ 201   67   87   11 1625   91   35]\n",
      " [ 527  216  183   10  111 3533    2]\n",
      " [  97  108  123  405   55    3 4356]]\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "     Assess Results       0.81      0.80      0.81      7488\n",
      "           Conclude       0.69      0.69      0.69      3057\n",
      "            Explore       0.82      0.83      0.83      5310\n",
      "              Focus       0.72      0.74      0.73      2051\n",
      "Generate Hypothesis       0.76      0.77      0.76      2117\n",
      "           Set Goal       0.78      0.77      0.78      4582\n",
      "    Test Hypothesis       0.85      0.85      0.85      5147\n",
      "\n",
      "           accuracy                           0.79     29752\n",
      "          macro avg       0.78      0.78      0.78     29752\n",
      "       weighted avg       0.79      0.79      0.79     29752\n",
      "\n",
      "\n",
      "Accuracy Score: 0.792551761226136\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier class\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train the Decision Tree model\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>With RandomizedSearchCV</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      "Best Parameters: {'min_samples_split': 12, 'min_samples_leaf': 20, 'max_depth': 14, 'ccp_alpha': 0.001}\n",
      "\n",
      "Accuracy Score: 0.567155149233665\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier class\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Define the parameter space for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'ccp_alpha': np.linspace(0.001, 0.5, 20),\n",
    "    'max_depth': list(range(1, 21)) + [None],\n",
    "    'min_samples_split': list(range(2, 21)),\n",
    "    'min_samples_leaf': list(range(1, 21))\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV instance\n",
    "random_search = RandomizedSearchCV(dt, param_dist, n_iter=100, cv=5, n_jobs=-1, random_state=42, verbose=1)\n",
    "\n",
    "# Train the model using the randomized search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nBest Parameters:\", random_search.best_params_)\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cross Validation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.36255261278633266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use 5-fold cross-validation to evaluate the model\n",
    "cv_scores = cross_val_score(dt, X_preprocessed, y, cv=5)\n",
    "print(\"Average cross-validation score:\", np.mean(cv_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
